# ðŸŽ¯ Phase 2 Implementation Plan - Core Squad Activation

**Status:** ðŸš€ IN PROGRESS
**Goal:** End-to-end test generation for a single endpoint (`/api/matches`)
**Timeline:** 4-6 hours
**Date:** November 8, 2025

---

## ðŸŽ¯ Phase 2 Objectives

### Primary Goal
Implement 4 agents that work together to **automatically generate complete test coverage** for `/api/matches` endpoint:

1. **ðŸŽ¯ ARCHITECT** - Designs test scenarios
2. **ðŸŽ¨ MOCKER** - Generates test data
3. **ðŸ”§ FORGE** - Generates api_client methods
4. **âš¡ FLASH** - Executes tests and reports coverage

### Success Criteria
- âœ… All 4 agents operational and working together
- âœ… Complete test file generated for `/api/matches`
- âœ… Missing api_client methods auto-generated
- âœ… Tests execute successfully
- âœ… Coverage increases measurably
- âœ… CLI command: `./crew_testing/run.sh generate /api/matches`

---

## ðŸ—ï¸ Architecture

### Sequential Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2 WORKFLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“š SWAGGER (existing)
   â”‚
   â”œâ”€â–º Scans /openapi.json
   â”œâ”€â–º Identifies /api/matches endpoint details
   â””â”€â–º Passes to ARCHITECT
        â”‚
        â”‚
ðŸŽ¯ ARCHITECT
   â”‚
   â”œâ”€â–º Receives endpoint spec from Swagger
   â”œâ”€â–º Designs test scenarios:
   â”‚   â€¢ Happy path (valid match)
   â”‚   â€¢ Error cases (missing fields, invalid IDs)
   â”‚   â€¢ Edge cases (date boundaries, same team)
   â”‚   â€¢ Security (unauthorized access)
   â””â”€â–º Passes scenarios to MOCKER
        â”‚
        â”‚
ðŸŽ¨ MOCKER
   â”‚
   â”œâ”€â–º Receives test scenarios
   â”œâ”€â–º Queries DB schema for FK relationships
   â”œâ”€â–º Generates test data:
   â”‚   â€¢ Valid matches with real team IDs
   â”‚   â€¢ Invalid data for error tests
   â”‚   â€¢ Edge case data
   â””â”€â–º Passes data + scenarios to FORGE & FLASH
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
ðŸ”§ FORGE              âš¡ FLASH           RESULTS
   â”‚                  â”‚                  â”‚
   â”œâ”€â–º Generates:    â”œâ”€â–º Executes:      â”œâ”€â–º Test file written
   â”‚   â€¢ Test file   â”‚   â€¢ pytest       â”‚   to backend/tests/
   â”‚   â€¢ api_client  â”‚   â€¢ Coverage     â”‚
   â”‚      methods    â”‚   â€¢ Report       â”œâ”€â–º api_client updated
   â”‚                 â”‚                  â”‚
   â””â”€â–º Writes code   â””â”€â–º Returns:       â””â”€â–º Coverage report
                         â€¢ Pass/fail        generated
                         â€¢ Coverage %
                         â€¢ Gaps found
```

---

## ðŸ› ï¸ Implementation Steps

### Step 1: Create Tools for Phase 2

**New tools needed:**

1. **`query_schema_tool.py`** - Database schema inspector
   - Query Supabase for table relationships
   - Return FK constraints
   - Identify required vs optional fields

2. **`code_generator_tool.py`** - Code generation utility
   - Generate Python test functions
   - Generate api_client methods
   - Use templates for consistency

3. **`pytest_runner_tool.py`** - Test execution
   - Run pytest with coverage
   - Parse output (pass/fail counts)
   - Return coverage percentage

4. **`file_writer_tool.py`** - Safe file operations
   - Write test files to backend/tests/
   - Update api_client/client.py
   - Backup before overwrite

### Step 2: Implement ARCHITECT Agent

**File:** `crew_testing/agents/architect.py`

**Responsibilities:**
- Receive endpoint spec from Swagger
- Design comprehensive test scenarios
- Consider:
  - HTTP methods (GET, POST, PUT, DELETE, PATCH)
  - Required vs optional parameters
  - Authentication requirements
  - Validation rules
  - Response codes (200, 201, 400, 401, 404, 500)

**Tools:**
- `read_openapi_spec` (existing)
- `detect_gaps` (existing)

**Output Format:**
```python
{
    "endpoint": "/api/matches",
    "scenarios": [
        {
            "name": "test_create_match_success",
            "description": "Valid match creation with existing teams",
            "method": "POST",
            "expected_status": 201,
            "requires_auth": True,
            "test_data_requirements": ["home_team_id", "away_team_id", "match_date"]
        },
        {
            "name": "test_create_match_missing_field",
            "description": "Missing required field returns 400",
            "method": "POST",
            "expected_status": 400,
            "requires_auth": True,
            "test_data_requirements": ["incomplete_data"]
        },
        # ... more scenarios
    ]
}
```

### Step 3: Implement MOCKER Agent

**File:** `crew_testing/agents/mocker.py`

**Responsibilities:**
- Receive test scenarios from Architect
- Generate appropriate test data for each
- Respect database constraints
- Create fixtures for pytest

**Tools:**
- `query_schema_tool` (new)
- `generate_test_data` (embedded logic)

**Output Format:**
```python
{
    "fixtures": {
        "valid_match_data": {
            "home_team_id": 1,
            "away_team_id": 2,
            "match_date": "2025-06-15",
            "season_id": 1,
            "age_group_id": 3,
            "division_id": 2
        },
        "invalid_match_missing_team": {
            "home_team_id": None,
            "away_team_id": 2,
            "match_date": "2025-06-15"
        }
    },
    "test_data_map": {
        "test_create_match_success": "valid_match_data",
        "test_create_match_missing_field": "invalid_match_missing_team"
    }
}
```

### Step 4: Implement FORGE Agent

**File:** `crew_testing/agents/forge.py`

**Responsibilities:**
- Generate test file from scenarios + data
- Generate missing api_client methods
- Use proper pytest conventions
- Include docstrings and type hints

**Tools:**
- `code_generator_tool` (new)
- `file_writer_tool` (new)

**Output:**
- `backend/tests/test_matches_generated.py`
- Updated `backend/api_client/client.py` with missing methods

**Test File Template:**
```python
\"\"\"
Auto-generated tests for /api/matches endpoint
Generated by: MT Testing Crew - Forge Agent
Date: 2025-11-08
\"\"\"

import pytest
from api_client import APIClient

@pytest.fixture
def valid_match_data():
    return {
        "home_team_id": 1,
        "away_team_id": 2,
        "match_date": "2025-06-15",
        # ...
    }

def test_create_match_success(api_client: APIClient, valid_match_data):
    \"\"\"Test successful match creation with valid data\"\"\"
    response = api_client.create_match(valid_match_data)
    assert response.status_code == 201
    assert "id" in response.json()
```

### Step 5: Implement FLASH Agent

**File:** `crew_testing/agents/flash.py`

**Responsibilities:**
- Execute generated tests
- Run with coverage tracking
- Parse pytest output
- Report results

**Tools:**
- `pytest_runner_tool` (new)

**Output Format:**
```python
{
    "total_tests": 15,
    "passed": 12,
    "failed": 3,
    "skipped": 0,
    "coverage_before": 51.2,
    "coverage_after": 68.5,
    "coverage_delta": +17.3,
    "duration_seconds": 8.2,
    "failed_tests": [
        {
            "name": "test_create_match_unauthorized",
            "error": "AssertionError: Expected 401, got 403"
        }
    ]
}
```

### Step 6: Create Phase 2 Orchestration

**File:** `crew_testing/crew_config.py` (update)

**New function:** `run_test_generation(endpoint: str)`

```python
def run_test_generation(endpoint: str) -> str:
    """
    Run Phase 2: Generate tests for a specific endpoint

    Workflow:
    1. Swagger scans endpoint details
    2. Architect designs test scenarios
    3. Mocker generates test data
    4. Forge generates code
    5. Flash executes and reports
    """

    # Create crew with sequential task execution
    crew = Crew(
        agents=[swagger_agent, architect_agent, mocker_agent, forge_agent, flash_agent],
        tasks=[scan_task, design_task, mock_task, forge_task, execute_task],
        process=Process.sequential,
        verbose=CrewConfig.VERBOSE
    )

    # Execute workflow
    result = crew.kickoff(inputs={"endpoint": endpoint})
    return result
```

### Step 7: Update CLI

**File:** `crew_testing/main.py`

**New command:**
```python
@app.command()
def generate(
    endpoint: str = typer.Argument(..., help="Endpoint to generate tests for (e.g., /api/matches)"),
    backend_url: str = typer.Option("http://localhost:8000", "--url", "-u"),
    verbose: bool = typer.Option(False, "--verbose", "-v")
):
    """
    ðŸ”§ Generate complete test coverage for an endpoint (Phase 2)

    This command runs the full Phase 2 crew:
    - Architect designs test scenarios
    - Mocker generates test data
    - Forge generates code (tests + api_client)
    - Flash executes and reports results
    """
    console.print(f"[bold blue]Generating tests for: {endpoint}[/bold blue]")

    result = run_test_generation(endpoint)

    console.print(Panel(result, title="Generation Complete", border_style="green"))
```

---

## ðŸ“Š Testing Strategy

### Unit Testing Each Agent

**Test each agent independently:**

```bash
# Test Architect
./crew_testing/run.sh test-architect /api/matches

# Test Mocker
./crew_testing/run.sh test-mocker /api/matches

# Test Forge
./crew_testing/run.sh test-forge /api/matches

# Test Flash
./crew_testing/run.sh test-flash
```

### Integration Testing

**Test the full workflow:**

```bash
# Generate tests for /api/matches
./crew_testing/run.sh generate /api/matches

# Expected output:
# ðŸŽ¯ Architect: Designing 15 test scenarios...
# ðŸŽ¨ Mocker: Generating test data...
# ðŸ”§ Forge: Writing test file...
# ðŸ”§ Forge: Updating api_client...
# âš¡ Flash: Executing 15 tests...
# âœ… Results: 12 passed, 3 failed
# ðŸ“Š Coverage: 51.2% â†’ 68.5% (+17.3%)
```

---

## ðŸ’° Cost Estimates

### Phase 2 LLM Costs

| Agent | LLM | Cost/Run | Why |
|-------|-----|----------|-----|
| Architect | GPT-4o | $0.20 | Complex reasoning for test design |
| Mocker | Claude Haiku | $0.05 | Data generation is straightforward |
| Forge | GPT-4o | $0.20 | Code generation requires intelligence |
| Flash | Claude Haiku | $0.05 | Test execution is procedural |
| **Total** | | **$0.50** | Per endpoint |

**Development costs:**
- Testing: ~10 runs Ã— $0.50 = $5.00
- Refinement: ~20 runs Ã— $0.50 = $10.00
- **Total Phase 2 dev:** ~$15.00

**Production usage:**
- Per endpoint: $0.50
- 73 endpoints: $36.50 (one-time for full coverage)

---

## ðŸŽ¯ Success Metrics

### Phase 2 Complete When:

- âœ… All 4 agents implemented and tested
- âœ… `./crew_testing/run.sh generate /api/matches` works end-to-end
- âœ… Generated test file is valid Python
- âœ… Generated api_client methods are functional
- âœ… Tests execute via pytest
- âœ… Coverage improvement is measurable
- âœ… Documentation updated
- âœ… PHASE2_COMPLETE.md written

### Demo-Ready Criteria:

- âœ… Can run live demo in < 2 minutes
- âœ… Output is visually impressive (rich formatting)
- âœ… Before/after coverage comparison is clear
- âœ… Generated code is readable and professional
- âœ… Error handling is graceful

---

## ðŸ“ Documentation Requirements

### Files to Create/Update:

1. **PHASE2_COMPLETE.md** - Phase 2 completion report
2. **PHASE2_ARCHITECTURE.md** - Technical deep dive
3. **README.md** - Update with Phase 2 commands
4. **TESTING_GUIDE.md** - Add Phase 2 testing scenarios
5. **IMPLEMENTATION_SUMMARY.md** - Update with Phase 2 details

---

## ðŸš€ Next Steps After Phase 2

### Phase 3: Intelligence Layer
- ðŸ”¬ Inspector - Analyze test patterns
- ðŸ“Š Herald - Generate beautiful reports
- ðŸ› Sherlock - Debug test failures

### Phase 4: Production Deployment
- GitHub Actions integration
- PR automation
- Demo video
- Interview presentation

---

## ðŸŽ¯ Let's Build!

**Starting with:** ARCHITECT agent
**Then:** MOCKER â†’ FORGE â†’ FLASH
**Timeline:** 4-6 hours total
**LFG!** ðŸš€

---

*Last Updated: November 8, 2025*
*Status: Implementation Starting*
*Phase: 2 of 4*
