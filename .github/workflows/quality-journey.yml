name: User Journey Tests

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options:
          - 'production'

env:
  PYTHON_VERSION: '3.13'
  S3_BUCKET: 'quality-missingtable-com'
  CLOUDFRONT_DISTRIBUTION_ID: 'E15AUGI7OKJ99L'

permissions:
  id-token: write   # Required for OIDC
  contents: read

jobs:
  journey-tests:
    name: Run User Journey Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-quality
          aws-region: us-east-1

      - name: Install Allure CLI
        run: |
          curl -fsSL https://github.com/allure-framework/allure2/releases/download/2.30.0/allure-2.30.0.tgz | tar -xz
          echo "$PWD/allure-2.30.0/bin" >> $GITHUB_PATH

      - name: Extract build info
        id: build-info
        run: |
          # Read version from VERSION file (matches production app format)
          APP_VERSION=$(cat VERSION 2>/dev/null || echo "0.0.0")
          # Use GitHub run number as build suffix (same as production CI/CD)
          VERSION="${APP_VERSION}.${{ github.run_number }}"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "branch=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          echo "Build version: $VERSION"
          echo "Branch: ${{ github.ref_name }}"

      - name: Verify Allure CLI
        run: |
          allure --version

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          uv sync

      - name: Run TSC Journey Tests
        id: journey-tests
        env:
          BASE_URL: https://api.missingtable.com
          TSC_PREFIX: tsc_ci_
          TSC_EXISTING_ADMIN_USERNAME: ${{ secrets.TSC_ADMIN_USERNAME }}
          TSC_EXISTING_ADMIN_PASSWORD: ${{ secrets.TSC_ADMIN_PASSWORD }}
        run: |
          cd backend
          mkdir -p allure-results
          uv run pytest tests/tsc/ \
            -v \
            -n 0 \
            --no-cov \
            --alluredir=allure-results \
            --ignore=tests/tsc/test_99_cleanup.py \
            || echo "TESTS_FAILED=true" >> $GITHUB_ENV
        continue-on-error: true

      - name: Run Cleanup (always)
        if: always()
        env:
          BASE_URL: https://api.missingtable.com
          TSC_PREFIX: tsc_ci_
          TSC_EXISTING_ADMIN_USERNAME: ${{ secrets.TSC_ADMIN_USERNAME }}
          TSC_EXISTING_ADMIN_PASSWORD: ${{ secrets.TSC_ADMIN_PASSWORD }}
        run: |
          cd backend
          uv run pytest tests/tsc/test_99_cleanup.py -v -n 0 --no-cov --alluredir=allure-results

      - name: Generate Allure Report
        if: always()
        run: |
          cd backend
          allure generate allure-results -o allure-report --clean

      - name: Add dashboard navigation to report
        if: always()
        env:
          BUILD_VERSION: ${{ steps.build-info.outputs.version }}
          BUILD_BRANCH: ${{ steps.build-info.outputs.branch }}
          COMMIT_SHA: ${{ github.sha }}
        run: |
          COMMIT_SHORT="${COMMIT_SHA:0:7}"
          BANNER="<div style=\"background:#2563eb;color:white;padding:8px 16px;font-family:-apple-system,BlinkMacSystemFont,sans-serif;font-size:14px;position:fixed;top:0;left:0;right:0;z-index:9999;display:flex;align-items:center;justify-content:space-between;\"><a href=\"https://quality.missingtable.com\" style=\"color:white;text-decoration:none;display:flex;align-items:center;gap:8px;\"><span style=\"font-size:18px;\">←</span> Back to Quality Dashboard</a><span style=\"opacity:0.9;\">Build ${BUILD_VERSION} · ${BUILD_BRANCH} · ${COMMIT_SHORT}</span></div><div style=\"height:40px;\"></div>"
          sed -i "s|<body>|<body>${BANNER}|" backend/allure-report/index.html

      - name: Extract journey metadata
        if: always()
        run: |
          cd backend
          uv run ../scripts/extract-run-metadata.py \
            --run-id ${{ github.run_id }} \
            --commit-sha ${{ github.sha }} \
            --trigger ${{ github.event_name }} \
            --workflow journey \
            --version "${{ steps.build-info.outputs.version }}" \
            --branch "${{ steps.build-info.outputs.branch }}" \
            --journey-allure-dir allure-report \
            --output /tmp/journey-metadata.json

      - name: Download history and compare runs
        if: always()
        run: |
          # Download existing history
          aws s3 cp s3://${S3_BUCKET}/data/history.json /tmp/history.json || echo '{"runs":[]}' > /tmp/history.json

          # Download previous run metadata for detailed comparison
          if [ -f /tmp/history.json ]; then
            PREV_RUN_ID=$(python3 -c "import json; h=json.load(open('/tmp/history.json')); print(h['runs'][0]['run_id'] if h.get('runs') else '')" 2>/dev/null || echo "")
            if [ -n "$PREV_RUN_ID" ]; then
              PREV_DATE=$(python3 -c "import json; from datetime import datetime; h=json.load(open('/tmp/history.json')); ts=h['runs'][0].get('timestamp',''); print(datetime.fromisoformat(ts.replace('Z','+00:00')).strftime('%Y-%m-%d') if ts else '')" 2>/dev/null || echo "")
              if [ -n "$PREV_DATE" ]; then
                aws s3 cp s3://${S3_BUCKET}/runs/missing-table/prod/${PREV_DATE}/${PREV_RUN_ID}/metadata.json /tmp/prev-metadata.json || true
              fi
            fi
          fi

          # Compare runs
          cd backend
          if [ -f /tmp/prev-metadata.json ]; then
            uv run ../scripts/compare-runs.py \
              --current /tmp/journey-metadata.json \
              --history /tmp/history.json \
              --previous-metadata /tmp/prev-metadata.json \
              --output /tmp/comparison.json
          else
            uv run ../scripts/compare-runs.py \
              --current /tmp/journey-metadata.json \
              --history /tmp/history.json \
              --output /tmp/comparison.json
          fi

          # Update history index with journey results
          uv run ../scripts/update-history-index.py \
            --current-run /tmp/journey-metadata.json \
            --history /tmp/history.json \
            --output /tmp/history.json \
            --max-runs 10

      - name: Upload to S3
        if: always()
        run: |
          # Upload latest journey report
          aws s3 sync backend/allure-report/ s3://${S3_BUCKET}/latest/missing-table/prod/journey/ \
            --delete \
            --cache-control "max-age=300"

          # Archive run report
          RUN_DATE=$(date -u +"%Y-%m-%d")
          aws s3 sync backend/allure-report/ s3://${S3_BUCKET}/runs/missing-table/prod/${RUN_DATE}/${{ github.run_id }}/journey/ \
            --cache-control "max-age=31536000"

          # Archive journey metadata
          aws s3 cp /tmp/journey-metadata.json \
            s3://${S3_BUCKET}/runs/missing-table/prod/${RUN_DATE}/${{ github.run_id }}/metadata.json \
            --cache-control "max-age=31536000"

          # Upload updated history index
          aws s3 cp /tmp/history.json s3://${S3_BUCKET}/data/history.json \
            --cache-control "max-age=300"

      - name: Download unit test results from S3
        if: always()
        run: |
          # Download existing unit test summaries to include in dashboard
          mkdir -p /tmp/backend-allure/widgets /tmp/data
          aws s3 cp s3://${S3_BUCKET}/latest/missing-table/prod/allure/widgets/summary.json /tmp/backend-allure/widgets/summary.json || true
          aws s3 cp s3://${S3_BUCKET}/latest/missing-table/prod/data/backend-coverage.json /tmp/data/backend-coverage.json || true
          aws s3 cp s3://${S3_BUCKET}/latest/missing-table/prod/data/frontend-results.json /tmp/data/frontend-results.json || true
          aws s3 cp s3://${S3_BUCKET}/latest/missing-table/prod/data/frontend-coverage.json /tmp/data/frontend-coverage.json || true

      - name: Update dashboard with journey stats
        if: always()
        run: |
          cd backend
          uv run ../scripts/generate-quality-dashboard.py \
            --output /tmp/index.html \
            --commit-sha ${{ github.sha }} \
            --run-id ${{ github.run_id }} \
            --backend-allure-dir /tmp/backend-allure \
            --backend-coverage-json /tmp/data/backend-coverage.json \
            --frontend-results-json /tmp/data/frontend-results.json \
            --frontend-coverage-json /tmp/data/frontend-coverage.json \
            --journey-allure-dir allure-report \
            --history-json /tmp/history.json \
            --comparison-json /tmp/comparison.json

          aws s3 cp /tmp/index.html s3://${S3_BUCKET}/index.html \
            --cache-control "max-age=300" \
            --content-type "text/html"

      - name: Invalidate CloudFront
        if: always()
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${CLOUDFRONT_DISTRIBUTION_ID} \
            --paths "/latest/missing-table/prod/journey/*" "/index.html"

      - name: Summary
        if: always()
        run: |
          # Extract test stats from Allure summary
          PASSED=$(python3 -c "import json; print(json.load(open('backend/allure-report/widgets/summary.json'))['statistic']['passed'])" 2>/dev/null || echo "N/A")
          TOTAL=$(python3 -c "import json; print(json.load(open('backend/allure-report/widgets/summary.json'))['statistic']['total'])" 2>/dev/null || echo "N/A")

          echo "### User Journey Tests Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** production (api.missingtable.com)" >> $GITHUB_STEP_SUMMARY
          echo "**Test Prefix:** tsc_ci_" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Results:** ${PASSED}/${TOTAL} tests passed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Reports:**" >> $GITHUB_STEP_SUMMARY
          echo "- [User Journey Report](https://quality.missingtable.com/latest/missing-table/prod/journey/)" >> $GITHUB_STEP_SUMMARY
          echo "- [Quality Dashboard](https://quality.missingtable.com)" >> $GITHUB_STEP_SUMMARY

      - name: Fail if tests failed
        if: env.TESTS_FAILED == 'true'
        run: exit 1
