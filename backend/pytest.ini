[pytest]
# ============================================================================
# pytest Configuration for Missing Table Backend
# ============================================================================

# Test Discovery
# ============================================================================
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test Markers
# ============================================================================
# Register all custom markers to avoid warnings
markers =
    unit: Unit tests - fast, isolated component tests
    integration: Integration tests - component interaction tests
    contract: Contract tests - API contract validation
    e2e: End-to-end tests - full user journey tests
    smoke: Smoke tests - critical path sanity checks
    slow: Tests that take more than 1 second
    auth: Authentication and authorization tests
    admin: Admin-only functionality tests
    database: Tests requiring database access
    external: Tests that call external services
    ai_generated: Tests generated by CrewAI agents
    skip_ci: Skip in CI pipeline
    requires_supabase: Requires Supabase to be running
    requires_redis: Requires Redis to be running
    flaky: Tests that occasionally fail (need investigation)
    backend: Backend-specific tests (legacy marker)
    api: API tests (legacy marker - use integration instead)
    dao: Data access object tests (legacy marker - use unit instead)
    invite: Invite-related tests (legacy marker)
    server: Server tests (legacy marker - use integration instead)
    standings: Standings/league table related tests
    matches: Match/game related tests
    critical: Critical path tests that must pass
    visual: Visual regression tests
    data_driven: Data-driven tests using parameterization
    filters: Filter-related tests
    security: Security-related tests
    responsive: Responsive design tests
    a11y: Accessibility tests

# Default Options
# ============================================================================
addopts =
    # Verbose output
    -v
    # Show extra test summary info
    -ra
    # Show local variables in tracebacks
    --showlocals
    # Strict marker checking (fail on unregistered markers)
    --strict-markers
    # Strict config checking
    --strict-config
    # Coverage options
    --cov=.
    --cov-report=html
    --cov-report=term-missing:skip-covered
    --cov-report=json
    # Fail if coverage is below threshold (commented out for now)
    # --cov-fail-under=75
    # Parallel execution (adjust -n based on CPU cores)
    -n auto
    # Capture output (use -s to disable for debugging)
    --capture=no
    # Show durations of slowest tests
    --durations=10
    # Traceback style
    --tb=short
    # Disable warnings summary (enable for debugging)
    --disable-warnings

# Warning Filters
# ============================================================================
filterwarnings =
    # Treat all warnings as errors (strict mode)
    # error
    # Ignore specific deprecation warnings we can't fix
    ignore::DeprecationWarning:gotrue
    ignore::DeprecationWarning:supafunc
    ignore::pydantic.PydanticDeprecatedSince20
    # Ignore test-related warnings
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::pytest.PytestAssertRewriteWarning

# Logging
# ============================================================================
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Asyncio
# ============================================================================
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Console Output
# ============================================================================
console_output_style = progress

# Timeout (optional - uncomment to enable)
# ============================================================================
# timeout = 300
# timeout_method = thread

# Minimum Python Version
# ============================================================================
minversion = 7.0

# Required Plugins
# ============================================================================
required_plugins =
    pytest-cov
    pytest-xdist
    pytest-asyncio

# ============================================================================
# Performance Tuning
# ============================================================================
# Cache test results for faster reruns
cache_dir = .pytest_cache

# ============================================================================
# Notes
# ============================================================================
# To run specific test categories:
#   pytest -m unit          # Run only unit tests
#   pytest -m integration   # Run only integration tests
#   pytest -m "not slow"    # Skip slow tests
#   pytest -m "smoke"       # Run only smoke tests
#
# To see available markers:
#   pytest --markers
#
# To run with specific coverage:
#   pytest --cov-fail-under=80
#
# To disable coverage (faster):
#   pytest --no-cov
